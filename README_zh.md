# tiny-rerankerï¼šåŸºäº Qwen3-0.6B çš„ ESCI å››æ¡£ç›¸å…³æ€§é‡æ’æ¨¡å‹

æœ¬ä»“åº“åœ¨ **Qwen3-0.6B** ä¸Šä½¿ç”¨ **LoRA**ï¼ŒåŸºäº **Amazon ESCI** æ•°æ®é›†è¿›è¡Œå¾®è°ƒï¼Œæ„å»ºä¸€ä¸ªé¢å‘ç”µå•†æœç´¢çš„ **å››åˆ†ç±»ç›¸å…³æ€§é‡æ’æ¨¡å‹**ã€‚

- ç¦»æ•£ç›¸å…³æ€§æ ‡ç­¾ï¼š**E / S / C / I**
  - **E**ï¼šexactï¼Œå®Œå…¨åŒ¹é…  
  - **S**ï¼šsubstituteï¼Œæ›¿ä»£å“  
  - **C**ï¼šcomplementï¼Œäº’è¡¥å“  
  - **I**ï¼širrelevantï¼Œä¸ç›¸å…³
- åŒæ—¶è¾“å‡ºä¸€ä¸ª **[0, 1] çš„è¿ç»­ç›¸å…³æ€§åˆ†æ•°**ï¼Œæ–¹ä¾¿ç”¨äºæ’åºã€AUC ç­‰è¯„ä¼°ã€‚

è®­ç»ƒé£æ ¼å‚è€ƒ **Qwen3-Reranker**ï¼šä½¿ç”¨ chat æ ¼å¼ promptï¼Œå¹¶åœ¨æœ€åä¸€ä¸ª token åšåˆ†ç±»é¢„æµ‹ã€‚

---

## ğŸ” è¿™ä¸ªé¡¹ç›®åœ¨åšä»€ä¹ˆï¼Ÿ

- æŠŠ **Qwen3-0.6B** å¾®è°ƒæˆ **ç†è§£ ESCI å››æ¡£çš„ reranker**ï¼›
- ä½¿ç”¨ **LoRA** è¿›è¡Œå‚æ•°é«˜æ•ˆå¾®è°ƒï¼Œæ˜¾å­˜éœ€æ±‚è¾ƒå°ï¼›
- æ¨¡å‹åœ¨æœ€åä¸€ä¸ª token å¤„é¢„æµ‹å››ä¸ª label ä¸­çš„ä¸€ä¸ªï¼š
  - `"exact"`, `"substitute"`, `"complement"`, `"irrelevant"`ï¼›
- æ¨ç†é˜¶æ®µè®¡ç®—ï¼š
  - å››åˆ†ç±»æ¦‚ç‡ï¼š`P(E), P(S), P(C), P(I)`ï¼›
  - ä¸€ä¸ªè¿ç»­ç›¸å…³æ€§åˆ†æ•°ï¼š
    $
    \text{score} = \frac{3P(E) + 2P(S) + 1P(C) + 0P(I)}{3}
    $
  - è¿™ä¸ªåˆ†æ•°å¯ä»¥ç›´æ¥ä½œä¸ºæ’åºä¿¡å·ã€‚

---

## ğŸ“‚ é¡¹ç›®ç»“æ„

```text
tiny-reranker/
â”œâ”€â”€ train.py          # LoRA å¾®è°ƒè„šæœ¬ï¼ˆåŸºäº ESCI å››åˆ†ç±»ï¼‰
â”œâ”€â”€ eval.py           # è¯„ä¼°è„šæœ¬ï¼ˆE/S/C/I + è¿ç»­ç›¸å…³æ€§åˆ†æ•°ï¼‰
â”œâ”€â”€ esci_dataset.py   # ESCI æ•°æ®é›†åŠ è½½ & prompt æ„é€ 
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ run_train.sh  # è®­ç»ƒè„šæœ¬ç¤ºä¾‹
â”‚   â””â”€â”€ run_eval.sh   # è¯„ä¼°è„šæœ¬ç¤ºä¾‹
â”œâ”€â”€ README.md
â””â”€â”€ README_zh.md
```

å…³é”®æ–‡ä»¶ï¼š
- esci_dataset.py
    - load_esci_parquet(path)ï¼šè¯»å–é¢„å¤„ç†å¥½çš„ parquet æ–‡ä»¶ï¼›
	- ESCIMultiClassRerankDatasetï¼šæ„é€  chat é£æ ¼è¾“å…¥ä¸æ ‡ç­¾ï¼›
	- LABEL_TEXT = {"E": "exact", "S": "substitute", "C": "complement", "I": "irrelevant"}ï¼›
	- SYSTEM_PROMPTã€INSTRUCTã€format_instruction(...)ï¼šå¯¹é½ Qwen3-Reranker çš„æç¤ºè¯æ ¼å¼ã€‚
- train.py
	- åŠ è½½ Qwen3-0.6Bï¼›
	- åœ¨æ³¨æ„åŠ›æŠ•å½±å±‚ï¼ˆå¦‚ q_proj, v_projï¼‰ä¸Šæ³¨å…¥ LoRAï¼›
	- é€šè¿‡ --train_file è¯»å– ESCI parquetï¼Œå¹¶ç”¨ --eval_ratio åœ¨å†…éƒ¨åˆ’åˆ† train / evalï¼›
	- ä½¿ç”¨ Hugging Face Trainer è¿›è¡Œè®­ç»ƒï¼Œå¯é€‰æ¥å…¥ wandb æ—¥å¿—ã€‚
- eval.py
	- åŠ è½½ base model + LoRA adapterï¼›
	- ç”¨ query + item_text æ„é€  promptï¼›
	- åœ¨æœ€åä¸€ä¸ª token çš„ logits ä¸Šï¼š
	- æå–å››ä¸ª label å¯¹åº” token çš„ logitsï¼›
	- å¯¹è¿™ 4 ä¸ª logits åš softmaxï¼Œå¾—åˆ° ESCI å››æ¡£æ¦‚ç‡ï¼›
	- è¾“å‡ºé¢„æµ‹ label + è¿ç»­ç›¸å…³æ€§åˆ†æ•°ã€‚

---

## ğŸ§± æ•°æ®å‡†å¤‡

æ•°æ®æ¥æºï¼šAmazon ESCI æ•°æ®é›†ï¼ˆè‹±æ–‡ï¼‰ã€‚

é¢„å¤„ç†åï¼Œå»ºè®® parquet æ–‡ä»¶åŒ…å«ä»¥ä¸‹å­—æ®µï¼š
- queryï¼šæœç´¢ queryï¼›
- item_textï¼šå•†å“ä¾§æ–‡æœ¬ï¼ˆå¦‚æ ‡é¢˜ + å“ç‰Œ + å±æ€§ ç­‰ï¼‰ï¼›
- esci_labelï¼šE / S / C / I å››æ¡£ä¹‹ä¸€ã€‚

ç¤ºä¾‹ä»£ç ï¼š

```python
from pathlib import Path
import pandas as pd

OUT_DIR = Path("../datasets/esci-data")
OUT_DIR.mkdir(parents=True, exist_ok=True)

df_train = ...  # ESCI è®­ç»ƒé›†
df_test = ...   # ESCI æµ‹è¯•é›†

df_train.to_parquet(OUT_DIR / "esci_multiclass_train.parquet", index=False)
df_test.to_parquet(OUT_DIR / "esci_multiclass_test.parquet", index=False)
```

æœ¬é¡¹ç›®ä¸­é»˜è®¤ä½¿ç”¨ï¼š
- ../datasets/esci-data/esci_multiclass_train.parquet
- ../datasets/esci-data/esci_multiclass_test.parquet

---

## âš™ï¸ ç¯å¢ƒé…ç½®

conda create -n tiny-reranker python=3.10 -y
conda activate tiny-reranker

å®‰è£…ä¾èµ–ï¼ˆæŒ‰éœ€ä¿®æ”¹ CUDA ç‰ˆæœ¬ï¼‰ï¼š

```bash
pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121
pip install transformers peft accelerate datasets pandas pyarrow scikit-learn tqdm
pip install wandb  # å¯é€‰ï¼šå¦‚éœ€æ¥å…¥ Weights & Biases

# å¦‚æœç¯å¢ƒæ”¯æŒ flash-attnï¼š

pip install flash-attn --no-build-isolation

# å¦‚ä¸æ”¯æŒï¼Œåœ¨è¿è¡Œè„šæœ¬æ—¶åŠ  --no_flash_attn å³å¯ã€‚
```

--- 

## ğŸš€ è®­ç»ƒï¼ˆTrainingï¼‰

å•å¡è®­ç»ƒç¤ºä¾‹

```bash
BASE_MODEL="../llms/Qwen/Qwen3-0.6B"
TRAIN_FILE="../datasets/esci-data/esci_multiclass_train.parquet"
OUTPUT_DIR="./outputs/qwen3_esci_reranker_lora"

MAX_LEN=512
BATCH_SIZE=4
GRAD_ACCUM=8
EPOCHS=1
LR=2e-4
WARMUP=0.03
LOGGING_STEPS=50
SAVE_STEPS=2000
SAVE_TOTAL_LIMIT=2
EVAL_RATIO=0.05   # ä¾‹å¦‚ï¼š5% æ ·æœ¬ä½œä¸ºéªŒè¯é›†

python train.py \
  --base_model "$BASE_MODEL" \
  --train_file "$TRAIN_FILE" \
  --output_dir "$OUTPUT_DIR" \
  --max_length $MAX_LEN \
  --per_device_train_batch_size $BATCH_SIZE \
  --gradient_accumulation_steps $GRAD_ACCUM \
  --num_train_epochs $EPOCHS \
  --learning_rate $LR \
  --warmup_ratio $WARMUP \
  --logging_steps $LOGGING_STEPS \
  --save_steps $SAVE_STEPS \
  --save_total_limit $SAVE_TOTAL_LIMIT \
  --lora_r 16 \
  --lora_alpha 32 \
  --lora_dropout 0.05 \
  --eval_ratio $EVAL_RATIO \
  --bf16
```

è¯´æ˜ï¼š
- --eval_ratioï¼šåœ¨ train_file é‡ŒæŒ‰æ¯”ä¾‹åˆ‡å‡ºéªŒè¯é›†ï¼›
- --save_total_limitï¼šæœ€å¤šä¿ç•™å¤šå°‘ä¸ª checkpointï¼Œæ—§çš„è‡ªåŠ¨åˆ é™¤ï¼›
- --bf16ï¼šä½¿ç”¨ bfloat16ï¼Œå¦‚ GPU ä¸æ”¯æŒå¯å»æ‰æ­¤å‚æ•°ã€‚

å¤šå¡è®­ç»ƒï¼ˆtorchrun + DDPï¼‰

```bash
export CUDA_VISIBLE_DEVICES=0,1
export NCCL_P2P_DISABLE=1
export NCCL_IB_DISABLE=1

torchrun --nnodes=1 --nproc_per_node=2 \
  train.py \
  --base_model "$BASE_MODEL" \
  --train_file "$TRAIN_FILE" \
  --output_dir "$OUTPUT_DIR" \
  --max_length $MAX_LEN \
  --per_device_train_batch_size $BATCH_SIZE \
  --gradient_accumulation_steps $GRAD_ACCUM \
  --num_train_epochs $EPOCHS \
  --learning_rate $LR \
  --warmup_ratio $WARMUP \
  --logging_steps $LOGGING_STEPS \
  --save_steps $SAVE_STEPS \
  --save_total_limit $SAVE_TOTAL_LIMIT \
  --lora_r 16 \
  --lora_alpha 32 \
  --lora_dropout 0.05 \
  --eval_ratio $EVAL_RATIO \
  --bf16
```

â¸»

ğŸ“ˆ è¯„ä¼°ï¼ˆEvaluationï¼‰

```bash
BASE_MODEL="../llms/Qwen/Qwen3-0.6B"
EVAL_FILE="../datasets/esci-data/esci_multiclass_test.parquet"
LORA_DIR="./outputs/qwen3_esci_reranker_lora"

MAX_LEN=512
BATCH_SIZE=16

python eval.py \
  --base_model "$BASE_MODEL" \
  --lora_model "$LORA_DIR" \
  --eval_file "$EVAL_FILE" \
  --max_length $MAX_LEN \
  --batch_size $BATCH_SIZE \
  --bf16
```

eval.py ä¼šï¼š
	â€¢	æ„é€  promptï¼Œè°ƒç”¨æ¨¡å‹å‰å‘ï¼›
	â€¢	æå–æœ€åä¸€ä¸ª token å¯¹åº”çš„ vocab logitsï¼›
	â€¢	å–å‡º "exact" / "substitute" / "complement" / "irrelevant" å››ä¸ª token çš„ logitsï¼Œåš softmax å¾—åˆ° ESCI å››æ¡£æ¦‚ç‡ï¼›
	â€¢	è¾“å‡ºï¼š
	â€¢	å››åˆ†ç±»å‡†ç¡®ç‡ï¼›
	â€¢	æ¯ä¸ªçœŸå®æ¡£ä½ä¸‹çš„å¹³å‡ç›¸å…³æ€§åˆ†æ•°ï¼›
	â€¢	è‹¥å¼€å¯ç›¸åº”ä»£ç ï¼Œè¿˜å¯è¾“å‡ºåˆ†ç±»æŠ¥å‘Š / æ··æ·†çŸ©é˜µï¼›
	â€¢	é€šè¿‡ --save_scores_path ä¿å­˜æ¯æ¡æ ·æœ¬çš„ label / score / probã€‚

---

## ğŸ“¡ Weights & Biases

```bash
wandb login
export WANDB_PROJECT=esci-qwen3-reranker
```

è®­ç»ƒæ—¶ï¼š

```bash
python train.py \
  ... \
  --report_to wandb \
  --wandb_run_name qwen3-esci-lora-v1
```

Trainer ä¼šè‡ªåŠ¨æŠŠ loss / eval æŒ‡æ ‡åŒæ­¥åˆ° W&Bã€‚